{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://www.geeksforgeeks.org/machine-learning/feature-selection-in-python-with-scikit-learn/",
   "id": "b055cb676ddcde81"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature Selection in Python with Scikit-Learn\n",
    "Last Updated : 23 Jul, 2025\n",
    "Feature selection is a crucial step in the machine learning pipeline. It involves selecting the most important features from your dataset to improve model performance and reduce computational cost. In this article, we will explore various techniques for feature selection in Python using the Scikit-Learn library.\n",
    "\n",
    "What is feature selection?\n",
    "Feature selection is the process of identifying and selecting a subset of relevant features for use in model construction. The goal is to enhance the model's performance by reducing overfitting, improving accuracy, and reducing training time.\n",
    "\n",
    "Why is Feature Selection Important?\n",
    "Feature selection offers several benefits:\n",
    "\n",
    "Improved Model Performance: By removing irrelevant or redundant features, we can improve the accuracy of the model.\n",
    "Reduced Overfitting: With fewer features, the model is less likely to learn noise from the training data.\n",
    "Faster Computation: Reducing the number of features decreases the computational cost and training time.\n",
    "Types of Feature Selection Methods\n",
    "\n",
    "Feature selection methods can be broadly classified into three categories:\n",
    "\n",
    "Filter Methods: Filter methods use statistical techniques to evaluate the relevance of features independently of the model. Common techniques include correlation coefficients, chi-square tests, and mutual information.\n",
    "Wrapper Methods: Wrapper methods use a predictive model to evaluate feature subsets and select the best-performing combination. Techniques include recursive feature elimination (RFE) and forward/backward feature selection.\n",
    "Embedded Methods: Embedded methods perform feature selection during the model training process. Examples include Lasso (L1 regularization) and feature importance from tree-based models.\n",
    "Feature Selection Techniques with Scikit-Learn\n",
    "Scikit-Learn provides several tools for feature selection, including:\n",
    "\n",
    "Univariate Selection: Univariate selection evaluates each feature individually to determine its importance. Techniques like SelectKBest and SelectPercentile can be used to select the top features based on statistical tests.\n",
    "Recursive Feature Elimination (RFE): RFE is a wrapper method that recursively removes the least important features based on a model's performance. It repeatedly builds a model and eliminates the weakest features until the desired number of features is reached.\n",
    "\n",
    "Feature Importance from Tree-based Models: Tree-based models like decision trees and random forests can provide feature importance scores, indicating the importance of each feature in making predictions.\n",
    "\n",
    "# Practical Implementation of Feature Selection with Scikit-Learn\n",
    "\n",
    "Let's implement these feature selection techniques using Scikit-Learn.\n",
    "\n",
    "Data Preparation:\n",
    "First, let's load a dataset and split it into features and target variables."
   ],
   "id": "4349dff0f54dba6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T22:53:53.219432Z",
     "start_time": "2025-12-14T22:53:53.135850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "id": "8c1a872b6064c412",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Method 1 : Univariate Selection in Python with Scikit-Learn\n",
    "\n",
    "We'll use SelectKBest with the chi-square test to select the top 2 features."
   ],
   "id": "563b46060ea1e8ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T22:53:53.250258Z",
     "start_time": "2025-12-14T22:53:53.220370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Apply SelectKBest with chi2\n",
    "select_k_best = SelectKBest(score_func=chi2, k=2)\n",
    "X_train_k_best = select_k_best.fit_transform(X_train, y_train)\n",
    "\n",
    "print(\"Selected features:\", X_train.columns[select_k_best.get_support()])"
   ],
   "id": "94a8ac36327327c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['petal length (cm)', 'petal width (cm)'], dtype='object')\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Method 2: Recursive Feature Elimination\n",
    "\n",
    "Next, we'll use RFE with a logistic regression model to select the top 2 features."
   ],
   "id": "8baf2e4415a7744"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T22:53:53.289201Z",
     "start_time": "2025-12-14T22:53:53.251598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Apply RFE with logistic regression\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "print(\"Selected features:\", X_train.columns[rfe.get_support()])"
   ],
   "id": "4b04188ea521237b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['petal length (cm)', 'petal width (cm)'], dtype='object')\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Method 3: Tree-Based Feature Importance\n",
    "\n",
    "Finally, we'll use a random forest classifier to determine feature importance."
   ],
   "id": "87294ae75ae4fbde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T22:53:53.432321Z",
     "start_time": "2025-12-14T22:53:53.290814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train random forest and get feature importances\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Display feature importances\n",
    "feature_importances = pd.Series(importances, index=X_train.columns)\n",
    "print(feature_importances.sort_values(ascending=False))"
   ],
   "id": "23827a58db4db3a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petal length (cm)    0.476168\n",
      "petal width (cm)     0.397886\n",
      "sepal length (cm)    0.081751\n",
      "sepal width (cm)     0.044195\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "Feature selection is an essential part of the machine learning workflow. By selecting the most relevant features, we can build more efficient and accurate models. Scikit-Learn provides a variety of tools to help with feature selection, including univariate selection, recursive feature elimination, and feature importance from tree-based models. Implementing these techniques can significantly improve your model's performance and computational efficiency.\n",
    "\n",
    "By following the steps outlined in this article, you can effectively perform feature selection in Python using Scikit-Learn, enhancing your machine learning projects and achieving better results."
   ],
   "id": "abc423aa8eb92c41"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
